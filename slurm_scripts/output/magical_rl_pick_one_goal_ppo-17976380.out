0:00:00 INFO: python -u train_rl.py -config configs/pick_one_goal_ppo.yaml -name pick_ppo_obs_only_17976380
0:00:00 INFO: 2023-03-01 15:22:48.330013
0:00:00 INFO: Write log to experiments/pick_ppo_obs_only_17976380/run.log
0:00:00 INFO: Config {
    name: 'pick_ppo_obs_only_17976380'
    view: 'ego'
    seed: 123
    device_id: 0
    one_goal: 1
    task: 'go_to_goal'
    num_cpu: 32
    config: 'configs/pick_one_goal_ppo.yaml'
    exp_root_dir: 'experiments'
    exp_dir: 'experiments/pick_ppo_obs_only_17976380'
    random: <random.Random object at 0x66ed2b0>
    start_time: 1677702168.3281517
}
Loading chipmunk for Linux (64bit) [/n/fs/nlp-kn5378/miniconda3/envs/magical/lib/python3.10/site-packages/pymunk/libchipmunk.so]
pygame 2.1.3 (SDL 2.0.22, Python 3.10.9)
Hello from the pygame community. https://www.pygame.org/contribute.html
Using cuda:0 device
Logging to experiments/pick_ppo_obs_only_17976380/PPO_1
/n/fs/nlp-kn5378/miniconda3/envs/magical/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:399: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7fe16efb9780> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fe16efb9240>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -6.39    |
| time/              |          |
|    fps             | 63       |
|    iterations      | 1        |
|    time_elapsed    | 40       |
|    total_timesteps | 2560     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.98       |
| time/                   |             |
|    fps                  | 56          |
|    iterations           | 2           |
|    time_elapsed         | 90          |
|    total_timesteps      | 5120        |
| train/                  |             |
|    approx_kl            | 0.013878981 |
|    clip_fraction        | 0.0762      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.88       |
|    explained_variance   | -0.0152     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0589      |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00693    |
|    value_loss           | 0.133       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.12       |
| time/                   |             |
|    fps                  | 54          |
|    iterations           | 3           |
|    time_elapsed         | 140         |
|    total_timesteps      | 7680        |
| train/                  |             |
|    approx_kl            | 0.015325126 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | -1.5e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.128       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0103     |
|    value_loss           | 0.253       |
-----------------------------------------
