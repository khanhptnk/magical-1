0:00:00 INFO: python -u train_rl.py -config configs/pick_ppo.yaml -name pick_ppo_17976269 -view ego
0:00:00 INFO: 2023-03-01 14:12:46.039332
0:00:00 INFO: Write log to experiments/pick_ppo_17976269/run.log
0:00:00 INFO: Config {
    name: 'pick_ppo_17976269'
    view: 'ego'
    seed: 123
    device_id: 0
    config: 'configs/pick_ppo.yaml'
    exp_root_dir: 'experiments'
    exp_dir: 'experiments/pick_ppo_17976269'
    random: <random.Random object at 0x70dc990>
    start_time: 1677697966.0375824
}
Loading chipmunk for Linux (64bit) [/n/fs/nlp-kn5378/miniconda3/envs/magical/lib/python3.10/site-packages/pymunk/libchipmunk.so]
pygame 2.1.3 (SDL 2.0.22, Python 3.10.9)
Hello from the pygame community. https://www.pygame.org/contribute.html
Using cuda:0 device
Logging to experiments/pick_ppo_17976269/PPO_1
/n/fs/nlp-kn5378/miniconda3/envs/magical/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:399: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f8e5cbcd1b0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f8e5cbcd240>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -6.38    |
| time/              |          |
|    fps             | 60       |
|    iterations      | 1        |
|    time_elapsed    | 42       |
|    total_timesteps | 2560     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.01       |
| time/                   |             |
|    fps                  | 52          |
|    iterations           | 2           |
|    time_elapsed         | 97          |
|    total_timesteps      | 5120        |
| train/                  |             |
|    approx_kl            | 0.013980103 |
|    clip_fraction        | 0.0736      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.88       |
|    explained_variance   | -0.0308     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0465      |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00659    |
|    value_loss           | 0.118       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.12       |
| time/                   |             |
|    fps                  | 49          |
|    iterations           | 3           |
|    time_elapsed         | 153         |
|    total_timesteps      | 7680        |
| train/                  |             |
|    approx_kl            | 0.015165796 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | 1.37e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.121       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0103     |
|    value_loss           | 0.233       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.99       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 4           |
|    time_elapsed         | 210         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.013115549 |
|    clip_fraction        | 0.0861      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.85       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.25        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00744    |
|    value_loss           | 0.468       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.99       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 5           |
|    time_elapsed         | 265         |
|    total_timesteps      | 12800       |
| train/                  |             |
|    approx_kl            | 0.009233272 |
|    clip_fraction        | 0.052       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.84       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.258       |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00447    |
|    value_loss           | 0.631       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.81       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 6           |
|    time_elapsed         | 323         |
|    total_timesteps      | 15360       |
| train/                  |             |
|    approx_kl            | 0.013612422 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0112     |
|    value_loss           | 0.701       |
-----------------------------------------
Eval num_timesteps=16000, episode_reward=-4.79 +/- 1.96
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -4.79       |
| time/                   |             |
|    total_timesteps      | 16000       |
| train/                  |             |
|    approx_kl            | 0.014534128 |
|    clip_fraction        | 0.0848      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.373       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00702    |
|    value_loss           | 0.773       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.86    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 7        |
|    time_elapsed    | 389      |
|    total_timesteps | 17920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.89       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 8           |
|    time_elapsed         | 444         |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.013334282 |
|    clip_fraction        | 0.095       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.399       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00851    |
|    value_loss           | 0.783       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.81       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 9           |
|    time_elapsed         | 501         |
|    total_timesteps      | 23040       |
| train/                  |             |
|    approx_kl            | 0.015733015 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.293       |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 0.903       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.74        |
| time/                   |              |
|    fps                  | 45           |
|    iterations           | 10           |
|    time_elapsed         | 556          |
|    total_timesteps      | 25600        |
| train/                  |              |
|    approx_kl            | 0.0117144715 |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.355        |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.0101      |
|    value_loss           | 0.827        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.69       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 11          |
|    time_elapsed         | 608         |
|    total_timesteps      | 28160       |
| train/                  |             |
|    approx_kl            | 0.015914649 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.539       |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00958    |
|    value_loss           | 0.813       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.78       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 12          |
|    time_elapsed         | 663         |
|    total_timesteps      | 30720       |
| train/                  |             |
|    approx_kl            | 0.013108173 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.433       |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00932    |
|    value_loss           | 0.831       |
-----------------------------------------
Eval num_timesteps=32000, episode_reward=-5.02 +/- 1.25
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -5.02       |
| time/                   |             |
|    total_timesteps      | 32000       |
| train/                  |             |
|    approx_kl            | 0.011667368 |
|    clip_fraction        | 0.0816      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.8        |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.338       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00638    |
|    value_loss           | 0.847       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.8     |
| time/              |          |
|    fps             | 45       |
|    iterations      | 13       |
|    time_elapsed    | 727      |
|    total_timesteps | 33280    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.78       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 14          |
|    time_elapsed         | 785         |
|    total_timesteps      | 35840       |
| train/                  |             |
|    approx_kl            | 0.014898224 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.481       |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00929    |
|    value_loss           | 0.912       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.89       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 15          |
|    time_elapsed         | 841         |
|    total_timesteps      | 38400       |
| train/                  |             |
|    approx_kl            | 0.015437536 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.384       |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.00945    |
|    value_loss           | 0.867       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.09       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 16          |
|    time_elapsed         | 898         |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 0.012973169 |
|    clip_fraction        | 0.0957      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.78       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.502       |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00779    |
|    value_loss           | 0.892       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -6.03      |
| time/                   |            |
|    fps                  | 45         |
|    iterations           | 17         |
|    time_elapsed         | 954        |
|    total_timesteps      | 43520      |
| train/                  |            |
|    approx_kl            | 0.01465294 |
|    clip_fraction        | 0.137      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.78      |
|    explained_variance   | -1.19e-07  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.484      |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.0115    |
|    value_loss           | 0.963      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.86       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 18          |
|    time_elapsed         | 1006        |
|    total_timesteps      | 46080       |
| train/                  |             |
|    approx_kl            | 0.012129528 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.78       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.502       |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.00847    |
|    value_loss           | 0.911       |
-----------------------------------------
Eval num_timesteps=48000, episode_reward=-5.59 +/- 1.86
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -5.59       |
| time/                   |             |
|    total_timesteps      | 48000       |
| train/                  |             |
|    approx_kl            | 0.012844312 |
|    clip_fraction        | 0.0813      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.77       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00671    |
|    value_loss           | 0.906       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.48    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 19       |
|    time_elapsed    | 1064     |
|    total_timesteps | 48640    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.73       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 20          |
|    time_elapsed         | 1116        |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 0.013368683 |
|    clip_fraction        | 0.0988      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.77       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.388       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00862    |
|    value_loss           | 0.866       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -5.94      |
| time/                   |            |
|    fps                  | 46         |
|    iterations           | 21         |
|    time_elapsed         | 1168       |
|    total_timesteps      | 53760      |
| train/                  |            |
|    approx_kl            | 0.01405582 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.76      |
|    explained_variance   | 5.96e-08   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.471      |
|    n_updates            | 200        |
|    policy_gradient_loss | -0.0114    |
|    value_loss           | 0.931      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -6.12      |
| time/                   |            |
|    fps                  | 46         |
|    iterations           | 22         |
|    time_elapsed         | 1220       |
|    total_timesteps      | 56320      |
| train/                  |            |
|    approx_kl            | 0.00910298 |
|    clip_fraction        | 0.0607     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.75      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.652      |
|    n_updates            | 210        |
|    policy_gradient_loss | -0.00534   |
|    value_loss           | 0.93       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.13       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 23          |
|    time_elapsed         | 1272        |
|    total_timesteps      | 58880       |
| train/                  |             |
|    approx_kl            | 0.012362678 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.71       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 0.957       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.88       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 24          |
|    time_elapsed         | 1324        |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.012259598 |
|    clip_fraction        | 0.0761      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.68       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.438       |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00646    |
|    value_loss           | 0.937       |
-----------------------------------------
Eval num_timesteps=64000, episode_reward=-6.00 +/- 0.38
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -6          |
| time/                   |             |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.009864753 |
|    clip_fraction        | 0.0525      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.67       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.508       |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00381    |
|    value_loss           | 0.895       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.61    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 25       |
|    time_elapsed    | 1381     |
|    total_timesteps | 64000    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.47       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 26          |
|    time_elapsed         | 1433        |
|    total_timesteps      | 66560       |
| train/                  |             |
|    approx_kl            | 0.012268024 |
|    clip_fraction        | 0.0816      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.66       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.456       |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00653    |
|    value_loss           | 0.807       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -5.63      |
| time/                   |            |
|    fps                  | 46         |
|    iterations           | 27         |
|    time_elapsed         | 1485       |
|    total_timesteps      | 69120      |
| train/                  |            |
|    approx_kl            | 0.01139492 |
|    clip_fraction        | 0.0452     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.65      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.476      |
|    n_updates            | 260        |
|    policy_gradient_loss | -0.00337   |
|    value_loss           | 0.852      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.86       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 28          |
|    time_elapsed         | 1537        |
|    total_timesteps      | 71680       |
| train/                  |             |
|    approx_kl            | 0.011002109 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.61       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.374       |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00827    |
|    value_loss           | 0.923       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.96       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 29          |
|    time_elapsed         | 1589        |
|    total_timesteps      | 74240       |
| train/                  |             |
|    approx_kl            | 0.012998506 |
|    clip_fraction        | 0.0729      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.57       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00629    |
|    value_loss           | 0.901       |
-----------------------------------------
srun: Job step aborted: Waiting up to 92 seconds for job step to finish.
slurmstepd: error: *** JOB 17976269 ON node030 CANCELLED AT 2023-03-01T14:40:12 ***
