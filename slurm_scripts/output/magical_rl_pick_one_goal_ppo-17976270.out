0:00:00 INFO: python -u train_rl.py -config configs/pick_one_goal_ppo.yaml -name pick_ppo_17976270
0:00:00 INFO: 2023-03-01 14:14:46.206151
0:00:00 INFO: Write log to experiments/pick_ppo_17976270/run.log
0:00:00 INFO: Config {
    name: 'pick_ppo_17976270'
    view: 'ego'
    seed: 123
    device_id: 0
    config: 'configs/pick_one_goal_ppo.yaml'
    exp_root_dir: 'experiments'
    exp_dir: 'experiments/pick_ppo_17976270'
    random: <random.Random object at 0x74df450>
    start_time: 1677698086.2042043
}
Loading chipmunk for Linux (64bit) [/n/fs/nlp-kn5378/miniconda3/envs/magical/lib/python3.10/site-packages/pymunk/libchipmunk.so]
pygame 2.1.3 (SDL 2.0.22, Python 3.10.9)
Hello from the pygame community. https://www.pygame.org/contribute.html
Using cuda:0 device
Logging to experiments/pick_ppo_17976270/PPO_1
/n/fs/nlp-kn5378/miniconda3/envs/magical/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:399: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7fec9584d1b0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fec9584d240>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -6.38    |
| time/              |          |
|    fps             | 56       |
|    iterations      | 1        |
|    time_elapsed    | 45       |
|    total_timesteps | 2560     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.01       |
| time/                   |             |
|    fps                  | 49          |
|    iterations           | 2           |
|    time_elapsed         | 102         |
|    total_timesteps      | 5120        |
| train/                  |             |
|    approx_kl            | 0.013980103 |
|    clip_fraction        | 0.0736      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.88       |
|    explained_variance   | -0.0308     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0465      |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00659    |
|    value_loss           | 0.118       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.12       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 3           |
|    time_elapsed         | 159         |
|    total_timesteps      | 7680        |
| train/                  |             |
|    approx_kl            | 0.015165796 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | 1.37e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.121       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0103     |
|    value_loss           | 0.233       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.99       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 4           |
|    time_elapsed         | 216         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.013115549 |
|    clip_fraction        | 0.0861      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.85       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.25        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00744    |
|    value_loss           | 0.468       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.99       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 5           |
|    time_elapsed         | 274         |
|    total_timesteps      | 12800       |
| train/                  |             |
|    approx_kl            | 0.009233272 |
|    clip_fraction        | 0.052       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.84       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.258       |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00447    |
|    value_loss           | 0.631       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.81       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 6           |
|    time_elapsed         | 330         |
|    total_timesteps      | 15360       |
| train/                  |             |
|    approx_kl            | 0.013612422 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0112     |
|    value_loss           | 0.701       |
-----------------------------------------
Eval num_timesteps=16000, episode_reward=-4.79 +/- 1.96
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -4.79       |
| time/                   |             |
|    total_timesteps      | 16000       |
| train/                  |             |
|    approx_kl            | 0.014534128 |
|    clip_fraction        | 0.0848      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.373       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00702    |
|    value_loss           | 0.773       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.86    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 7        |
|    time_elapsed    | 394      |
|    total_timesteps | 17920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.89       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 8           |
|    time_elapsed         | 448         |
|    total_timesteps      | 20480       |
| train/                  |             |
|    approx_kl            | 0.013334282 |
|    clip_fraction        | 0.095       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.399       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00851    |
|    value_loss           | 0.783       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.81       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 9           |
|    time_elapsed         | 500         |
|    total_timesteps      | 23040       |
| train/                  |             |
|    approx_kl            | 0.015733015 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.293       |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 0.903       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.74        |
| time/                   |              |
|    fps                  | 46           |
|    iterations           | 10           |
|    time_elapsed         | 556          |
|    total_timesteps      | 25600        |
| train/                  |              |
|    approx_kl            | 0.0117144715 |
|    clip_fraction        | 0.109        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.355        |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.0101      |
|    value_loss           | 0.827        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.69       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 11          |
|    time_elapsed         | 613         |
|    total_timesteps      | 28160       |
| train/                  |             |
|    approx_kl            | 0.015914649 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.539       |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00958    |
|    value_loss           | 0.813       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.78       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 12          |
|    time_elapsed         | 669         |
|    total_timesteps      | 30720       |
| train/                  |             |
|    approx_kl            | 0.013108173 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.433       |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00932    |
|    value_loss           | 0.831       |
-----------------------------------------
Eval num_timesteps=32000, episode_reward=-5.02 +/- 1.25
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -5.02       |
| time/                   |             |
|    total_timesteps      | 32000       |
| train/                  |             |
|    approx_kl            | 0.011667368 |
|    clip_fraction        | 0.0816      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.8        |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.338       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00638    |
|    value_loss           | 0.847       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.8     |
| time/              |          |
|    fps             | 45       |
|    iterations      | 13       |
|    time_elapsed    | 734      |
|    total_timesteps | 33280    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.78       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 14          |
|    time_elapsed         | 791         |
|    total_timesteps      | 35840       |
| train/                  |             |
|    approx_kl            | 0.014898224 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.481       |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00929    |
|    value_loss           | 0.912       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.89       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 15          |
|    time_elapsed         | 845         |
|    total_timesteps      | 38400       |
| train/                  |             |
|    approx_kl            | 0.015437536 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.384       |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.00945    |
|    value_loss           | 0.867       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.09       |
| time/                   |             |
|    fps                  | 45          |
|    iterations           | 16          |
|    time_elapsed         | 897         |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 0.012973169 |
|    clip_fraction        | 0.0957      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.78       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.502       |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00779    |
|    value_loss           | 0.892       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -6.03      |
| time/                   |            |
|    fps                  | 45         |
|    iterations           | 17         |
|    time_elapsed         | 949        |
|    total_timesteps      | 43520      |
| train/                  |            |
|    approx_kl            | 0.01465294 |
|    clip_fraction        | 0.137      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.78      |
|    explained_variance   | -1.19e-07  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.484      |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.0115    |
|    value_loss           | 0.963      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.86       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 18          |
|    time_elapsed         | 1001        |
|    total_timesteps      | 46080       |
| train/                  |             |
|    approx_kl            | 0.012129528 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.78       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.502       |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.00847    |
|    value_loss           | 0.911       |
-----------------------------------------
Eval num_timesteps=48000, episode_reward=-5.59 +/- 1.86
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -5.59       |
| time/                   |             |
|    total_timesteps      | 48000       |
| train/                  |             |
|    approx_kl            | 0.012844312 |
|    clip_fraction        | 0.0813      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.77       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00671    |
|    value_loss           | 0.906       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.48    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 19       |
|    time_elapsed    | 1059     |
|    total_timesteps | 48640    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.73       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 20          |
|    time_elapsed         | 1111        |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 0.013368683 |
|    clip_fraction        | 0.0988      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.77       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.388       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00862    |
|    value_loss           | 0.866       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -5.94      |
| time/                   |            |
|    fps                  | 46         |
|    iterations           | 21         |
|    time_elapsed         | 1162       |
|    total_timesteps      | 53760      |
| train/                  |            |
|    approx_kl            | 0.01405582 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.76      |
|    explained_variance   | 5.96e-08   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.471      |
|    n_updates            | 200        |
|    policy_gradient_loss | -0.0114    |
|    value_loss           | 0.931      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -6.12      |
| time/                   |            |
|    fps                  | 46         |
|    iterations           | 22         |
|    time_elapsed         | 1214       |
|    total_timesteps      | 56320      |
| train/                  |            |
|    approx_kl            | 0.00910298 |
|    clip_fraction        | 0.0607     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.75      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.652      |
|    n_updates            | 210        |
|    policy_gradient_loss | -0.00534   |
|    value_loss           | 0.93       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.13       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 23          |
|    time_elapsed         | 1266        |
|    total_timesteps      | 58880       |
| train/                  |             |
|    approx_kl            | 0.012362678 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.71       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0106     |
|    value_loss           | 0.957       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.88       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 24          |
|    time_elapsed         | 1318        |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 0.012259598 |
|    clip_fraction        | 0.0761      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.68       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.438       |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00646    |
|    value_loss           | 0.937       |
-----------------------------------------
Eval num_timesteps=64000, episode_reward=-6.00 +/- 0.38
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -6          |
| time/                   |             |
|    total_timesteps      | 64000       |
| train/                  |             |
|    approx_kl            | 0.009864753 |
|    clip_fraction        | 0.0525      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.67       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.508       |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00381    |
|    value_loss           | 0.895       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.61    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 25       |
|    time_elapsed    | 1376     |
|    total_timesteps | 64000    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.47       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 26          |
|    time_elapsed         | 1428        |
|    total_timesteps      | 66560       |
| train/                  |             |
|    approx_kl            | 0.012268024 |
|    clip_fraction        | 0.0816      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.66       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.456       |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00653    |
|    value_loss           | 0.807       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -5.63      |
| time/                   |            |
|    fps                  | 46         |
|    iterations           | 27         |
|    time_elapsed         | 1479       |
|    total_timesteps      | 69120      |
| train/                  |            |
|    approx_kl            | 0.01139492 |
|    clip_fraction        | 0.0452     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.65      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.476      |
|    n_updates            | 260        |
|    policy_gradient_loss | -0.00337   |
|    value_loss           | 0.852      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.86       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 28          |
|    time_elapsed         | 1530        |
|    total_timesteps      | 71680       |
| train/                  |             |
|    approx_kl            | 0.011002109 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.61       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.374       |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00827    |
|    value_loss           | 0.923       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.96       |
| time/                   |             |
|    fps                  | 46          |
|    iterations           | 29          |
|    time_elapsed         | 1580        |
|    total_timesteps      | 74240       |
| train/                  |             |
|    approx_kl            | 0.012998506 |
|    clip_fraction        | 0.0729      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.57       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00629    |
|    value_loss           | 0.901       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.75       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 30          |
|    time_elapsed         | 1631        |
|    total_timesteps      | 76800       |
| train/                  |             |
|    approx_kl            | 0.011668414 |
|    clip_fraction        | 0.0658      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.57       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.381       |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.00515    |
|    value_loss           | 0.911       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.64        |
| time/                   |              |
|    fps                  | 47           |
|    iterations           | 31           |
|    time_elapsed         | 1681         |
|    total_timesteps      | 79360        |
| train/                  |              |
|    approx_kl            | 0.0145021705 |
|    clip_fraction        | 0.0675       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.288        |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.0057      |
|    value_loss           | 0.887        |
------------------------------------------
Eval num_timesteps=80000, episode_reward=-4.92 +/- 0.78
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -4.92       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.013637243 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.57       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.374       |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.00963    |
|    value_loss           | 0.857       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.69    |
| time/              |          |
|    fps             | 47       |
|    iterations      | 32       |
|    time_elapsed    | 1738     |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.78       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 33          |
|    time_elapsed         | 1788        |
|    total_timesteps      | 84480       |
| train/                  |             |
|    approx_kl            | 0.017564243 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.53       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.381       |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0101     |
|    value_loss           | 0.88        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.94       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 34          |
|    time_elapsed         | 1839        |
|    total_timesteps      | 87040       |
| train/                  |             |
|    approx_kl            | 0.013650907 |
|    clip_fraction        | 0.072       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.56       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.635       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.00602    |
|    value_loss           | 0.906       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.86       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 35          |
|    time_elapsed         | 1890        |
|    total_timesteps      | 89600       |
| train/                  |             |
|    approx_kl            | 0.011781672 |
|    clip_fraction        | 0.0543      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.54       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.449       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00482    |
|    value_loss           | 0.9         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.68        |
| time/                   |              |
|    fps                  | 47           |
|    iterations           | 36           |
|    time_elapsed         | 1941         |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0111752795 |
|    clip_fraction        | 0.0763       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.252        |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00677     |
|    value_loss           | 0.927        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.6        |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 37          |
|    time_elapsed         | 1992        |
|    total_timesteps      | 94720       |
| train/                  |             |
|    approx_kl            | 0.013237119 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.54       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.424       |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.00898    |
|    value_loss           | 0.832       |
-----------------------------------------
Eval num_timesteps=96000, episode_reward=-4.93 +/- 1.17
Episode length: 80.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 80           |
|    mean_reward          | -4.93        |
| time/                   |              |
|    total_timesteps      | 96000        |
| train/                  |              |
|    approx_kl            | 0.0060665905 |
|    clip_fraction        | 0.0551       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.405        |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00472     |
|    value_loss           | 0.883        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.68    |
| time/              |          |
|    fps             | 47       |
|    iterations      | 38       |
|    time_elapsed    | 2048     |
|    total_timesteps | 97280    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.73       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 39          |
|    time_elapsed         | 2099        |
|    total_timesteps      | 99840       |
| train/                  |             |
|    approx_kl            | 0.013433057 |
|    clip_fraction        | 0.0812      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.49       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.577       |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0064     |
|    value_loss           | 0.885       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.64       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 40          |
|    time_elapsed         | 2150        |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.015170252 |
|    clip_fraction        | 0.0884      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.52       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.425       |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.00776    |
|    value_loss           | 0.872       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -5.6       |
| time/                   |            |
|    fps                  | 47         |
|    iterations           | 41         |
|    time_elapsed         | 2201       |
|    total_timesteps      | 104960     |
| train/                  |            |
|    approx_kl            | 0.01481995 |
|    clip_fraction        | 0.086      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.53      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.523      |
|    n_updates            | 400        |
|    policy_gradient_loss | -0.0081    |
|    value_loss           | 0.853      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.82       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 42          |
|    time_elapsed         | 2252        |
|    total_timesteps      | 107520      |
| train/                  |             |
|    approx_kl            | 0.015843388 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.451       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00911    |
|    value_loss           | 0.832       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.97       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 43          |
|    time_elapsed         | 2304        |
|    total_timesteps      | 110080      |
| train/                  |             |
|    approx_kl            | 0.013011393 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.323       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00929    |
|    value_loss           | 0.894       |
-----------------------------------------
Eval num_timesteps=112000, episode_reward=-6.12 +/- 1.33
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -6.12       |
| time/                   |             |
|    total_timesteps      | 112000      |
| train/                  |             |
|    approx_kl            | 0.008285639 |
|    clip_fraction        | 0.0472      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.47       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.489       |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.003      |
|    value_loss           | 0.904       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.95    |
| time/              |          |
|    fps             | 47       |
|    iterations      | 44       |
|    time_elapsed    | 2359     |
|    total_timesteps | 112640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.86       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 45          |
|    time_elapsed         | 2410        |
|    total_timesteps      | 115200      |
| train/                  |             |
|    approx_kl            | 0.010660619 |
|    clip_fraction        | 0.082       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.53       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.453       |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00657    |
|    value_loss           | 0.901       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.7        |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 46          |
|    time_elapsed         | 2459        |
|    total_timesteps      | 117760      |
| train/                  |             |
|    approx_kl            | 0.014946503 |
|    clip_fraction        | 0.0816      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.5        |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.426       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00691    |
|    value_loss           | 0.934       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.86       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 47          |
|    time_elapsed         | 2509        |
|    total_timesteps      | 120320      |
| train/                  |             |
|    approx_kl            | 0.013889313 |
|    clip_fraction        | 0.0866      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.49       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.512       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00684    |
|    value_loss           | 0.886       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.99       |
| time/                   |             |
|    fps                  | 47          |
|    iterations           | 48          |
|    time_elapsed         | 2560        |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.015910804 |
|    clip_fraction        | 0.0731      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.45       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.401       |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00587    |
|    value_loss           | 0.915       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.02       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 49          |
|    time_elapsed         | 2610        |
|    total_timesteps      | 125440      |
| train/                  |             |
|    approx_kl            | 0.009989475 |
|    clip_fraction        | 0.0378      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.43       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.393       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00345    |
|    value_loss           | 0.974       |
-----------------------------------------
Eval num_timesteps=128000, episode_reward=-6.93 +/- 1.65
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -6.93       |
| time/                   |             |
|    total_timesteps      | 128000      |
| train/                  |             |
|    approx_kl            | 0.015665008 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.38       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.507       |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0111     |
|    value_loss           | 0.928       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.86    |
| time/              |          |
|    fps             | 48       |
|    iterations      | 50       |
|    time_elapsed    | 2666     |
|    total_timesteps | 128000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.7         |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 51           |
|    time_elapsed         | 2717         |
|    total_timesteps      | 130560       |
| train/                  |              |
|    approx_kl            | 0.0118094105 |
|    clip_fraction        | 0.0794       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.314        |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.00625     |
|    value_loss           | 0.907        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.81       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 52          |
|    time_elapsed         | 2768        |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.014111635 |
|    clip_fraction        | 0.0986      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.32       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.461       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00862    |
|    value_loss           | 0.86        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.77       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 53          |
|    time_elapsed         | 2818        |
|    total_timesteps      | 135680      |
| train/                  |             |
|    approx_kl            | 0.012146776 |
|    clip_fraction        | 0.0519      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.26       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.49        |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00423    |
|    value_loss           | 0.878       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.81        |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 54           |
|    time_elapsed         | 2868         |
|    total_timesteps      | 138240       |
| train/                  |              |
|    approx_kl            | 0.0076407837 |
|    clip_fraction        | 0.047        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.414        |
|    n_updates            | 530          |
|    policy_gradient_loss | -0.004       |
|    value_loss           | 0.913        |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -5.79      |
| time/                   |            |
|    fps                  | 48         |
|    iterations           | 55         |
|    time_elapsed         | 2918       |
|    total_timesteps      | 140800     |
| train/                  |            |
|    approx_kl            | 0.00961011 |
|    clip_fraction        | 0.0536     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.26      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.293      |
|    n_updates            | 540        |
|    policy_gradient_loss | -0.00482   |
|    value_loss           | 0.864      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.71       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 56          |
|    time_elapsed         | 2968        |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.015245387 |
|    clip_fraction        | 0.0857      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.23       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.336       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.00842    |
|    value_loss           | 0.884       |
-----------------------------------------
Eval num_timesteps=144000, episode_reward=-5.16 +/- 1.32
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -5.16       |
| time/                   |             |
|    total_timesteps      | 144000      |
| train/                  |             |
|    approx_kl            | 0.010597565 |
|    clip_fraction        | 0.0945      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.2        |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.446       |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00802    |
|    value_loss           | 0.881       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.66    |
| time/              |          |
|    fps             | 48       |
|    iterations      | 57       |
|    time_elapsed    | 3024     |
|    total_timesteps | 145920   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.67        |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 58           |
|    time_elapsed         | 3074         |
|    total_timesteps      | 148480       |
| train/                  |              |
|    approx_kl            | 0.0083839055 |
|    clip_fraction        | 0.0607       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.462        |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.00559     |
|    value_loss           | 0.901        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.69       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 59          |
|    time_elapsed         | 3125        |
|    total_timesteps      | 151040      |
| train/                  |             |
|    approx_kl            | 0.015222535 |
|    clip_fraction        | 0.0684      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.356       |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00583    |
|    value_loss           | 0.881       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.71       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 60          |
|    time_elapsed         | 3175        |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.008591473 |
|    clip_fraction        | 0.0775      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.475       |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00644    |
|    value_loss           | 0.884       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -5.65      |
| time/                   |            |
|    fps                  | 48         |
|    iterations           | 61         |
|    time_elapsed         | 3226       |
|    total_timesteps      | 156160     |
| train/                  |            |
|    approx_kl            | 0.01319511 |
|    clip_fraction        | 0.0602     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.98      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.404      |
|    n_updates            | 600        |
|    policy_gradient_loss | -0.00477   |
|    value_loss           | 0.853      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.82       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 62          |
|    time_elapsed         | 3277        |
|    total_timesteps      | 158720      |
| train/                  |             |
|    approx_kl            | 0.008764631 |
|    clip_fraction        | 0.0624      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.433       |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00528    |
|    value_loss           | 0.849       |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-7.13 +/- 1.66
Episode length: 80.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 80           |
|    mean_reward          | -7.13        |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0072384058 |
|    clip_fraction        | 0.0539       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.8         |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.442        |
|    n_updates            | 620          |
|    policy_gradient_loss | -0.00445     |
|    value_loss           | 0.882        |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.96    |
| time/              |          |
|    fps             | 48       |
|    iterations      | 63       |
|    time_elapsed    | 3335     |
|    total_timesteps | 161280   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -6.21        |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 64           |
|    time_elapsed         | 3386         |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0076430007 |
|    clip_fraction        | 0.0597       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.74        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.479        |
|    n_updates            | 630          |
|    policy_gradient_loss | -0.00411     |
|    value_loss           | 0.951        |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -6.22      |
| time/                   |            |
|    fps                  | 48         |
|    iterations           | 65         |
|    time_elapsed         | 3438       |
|    total_timesteps      | 166400     |
| train/                  |            |
|    approx_kl            | 0.00720436 |
|    clip_fraction        | 0.0584     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.77      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.403      |
|    n_updates            | 640        |
|    policy_gradient_loss | -0.00487   |
|    value_loss           | 0.975      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.28       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 66          |
|    time_elapsed         | 3489        |
|    total_timesteps      | 168960      |
| train/                  |             |
|    approx_kl            | 0.008156225 |
|    clip_fraction        | 0.0494      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.776       |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.00456    |
|    value_loss           | 0.981       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -6.2         |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 67           |
|    time_elapsed         | 3541         |
|    total_timesteps      | 171520       |
| train/                  |              |
|    approx_kl            | 0.0070496937 |
|    clip_fraction        | 0.0541       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.69        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.541        |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.00523     |
|    value_loss           | 1.02         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -6.09       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 68          |
|    time_elapsed         | 3592        |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.007130994 |
|    clip_fraction        | 0.0582      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.61       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.632       |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.00471    |
|    value_loss           | 1.02        |
-----------------------------------------
Eval num_timesteps=176000, episode_reward=-6.66 +/- 1.14
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -6.66       |
| time/                   |             |
|    total_timesteps      | 176000      |
| train/                  |             |
|    approx_kl            | 0.006418617 |
|    clip_fraction        | 0.0484      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.572       |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.00355    |
|    value_loss           | 0.967       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.76    |
| time/              |          |
|    fps             | 48       |
|    iterations      | 69       |
|    time_elapsed    | 3650     |
|    total_timesteps | 176640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80         |
|    ep_rew_mean          | -5.83      |
| time/                   |            |
|    fps                  | 48         |
|    iterations           | 70         |
|    time_elapsed         | 3701       |
|    total_timesteps      | 179200     |
| train/                  |            |
|    approx_kl            | 0.00643398 |
|    clip_fraction        | 0.0694     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.61      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.407      |
|    n_updates            | 690        |
|    policy_gradient_loss | -0.00553   |
|    value_loss           | 0.9        |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.86        |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 71           |
|    time_elapsed         | 3752         |
|    total_timesteps      | 181760       |
| train/                  |              |
|    approx_kl            | 0.0065512024 |
|    clip_fraction        | 0.0581       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.58        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.538        |
|    n_updates            | 700          |
|    policy_gradient_loss | -0.00543     |
|    value_loss           | 0.921        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -6.03        |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 72           |
|    time_elapsed         | 3803         |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 0.0055009485 |
|    clip_fraction        | 0.03         |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.62        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.502        |
|    n_updates            | 710          |
|    policy_gradient_loss | -0.00293     |
|    value_loss           | 0.918        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -6           |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 73           |
|    time_elapsed         | 3855         |
|    total_timesteps      | 186880       |
| train/                  |              |
|    approx_kl            | 0.0051324666 |
|    clip_fraction        | 0.0673       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.65        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.471        |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.0066      |
|    value_loss           | 0.956        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.86       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 74          |
|    time_elapsed         | 3906        |
|    total_timesteps      | 189440      |
| train/                  |             |
|    approx_kl            | 0.008281251 |
|    clip_fraction        | 0.0532      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.548       |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.00375    |
|    value_loss           | 0.973       |
-----------------------------------------
Eval num_timesteps=192000, episode_reward=-6.60 +/- 1.47
Episode length: 80.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 80          |
|    mean_reward          | -6.6        |
| time/                   |             |
|    total_timesteps      | 192000      |
| train/                  |             |
|    approx_kl            | 0.006440914 |
|    clip_fraction        | 0.0571      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.437       |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0048     |
|    value_loss           | 0.922       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | -5.79    |
| time/              |          |
|    fps             | 48       |
|    iterations      | 75       |
|    time_elapsed    | 3964     |
|    total_timesteps | 192000   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.87        |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 76           |
|    time_elapsed         | 4015         |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 0.0069462536 |
|    clip_fraction        | 0.0304       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.54        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.306        |
|    n_updates            | 750          |
|    policy_gradient_loss | -0.00304     |
|    value_loss           | 0.915        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80          |
|    ep_rew_mean          | -5.79       |
| time/                   |             |
|    fps                  | 48          |
|    iterations           | 77          |
|    time_elapsed         | 4067        |
|    total_timesteps      | 197120      |
| train/                  |             |
|    approx_kl            | 0.007830878 |
|    clip_fraction        | 0.0547      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.628       |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00493    |
|    value_loss           | 0.919       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.81        |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 78           |
|    time_elapsed         | 4118         |
|    total_timesteps      | 199680       |
| train/                  |              |
|    approx_kl            | 0.0051619196 |
|    clip_fraction        | 0.029        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.29        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.513        |
|    n_updates            | 770          |
|    policy_gradient_loss | -0.0023      |
|    value_loss           | 0.883        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.63        |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 79           |
|    time_elapsed         | 4169         |
|    total_timesteps      | 202240       |
| train/                  |              |
|    approx_kl            | 0.0039265943 |
|    clip_fraction        | 0.0452       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.23        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.553        |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.00392     |
|    value_loss           | 0.896        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 80           |
|    ep_rew_mean          | -5.52        |
| time/                   |              |
|    fps                  | 48           |
|    iterations           | 80           |
|    time_elapsed         | 4220         |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 0.0037488476 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.29        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0003       |
|    loss                 | 0.501        |
|    n_updates            | 790          |
|    policy_gradient_loss | -0.00252     |
|    value_loss           | 0.872        |
------------------------------------------
